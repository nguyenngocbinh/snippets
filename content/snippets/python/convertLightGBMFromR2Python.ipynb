{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Convert the MLR3 LightGBM model from R to Python\n",
    "author: \"Nguyễn Ngọc Bình\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Example LightGBM model is created by MLR3 in R\n",
    "\n",
    "Buile LightGBM model by the following steps:\n",
    "\n",
    "1. Loads the necessary libraries for mlr3, LightGBM, and data manipulation.\n",
    "2. Sets the logging threshold for mlr3 to the warning level.\n",
    "3. Loads the German Credit dataset and creates a classification task.\n",
    "4. Defines a preprocessing pipeline with specific operations such as imputation, encoding, and feature filtering.\n",
    "5. Sets parameter values for the preprocessing steps (e.g., filter fraction).\n",
    "6. Defines a LightGBM learner with a specified number of iterations.\n",
    "7. Combines the preprocessing and learner into a single pipeline.\n",
    "8. Creates a GraphLearner to encapsulate the pipeline.\n",
    "9. Trains the model on the classification task.\n",
    "10. Makes predictions on the task using the trained model.\n",
    "11. Extracts the LightGBM model from the pipeline.\n",
    "12. Specifies a filename for saving the LightGBM model.\n",
    "13. Saves the LightGBM model to a file.\n",
    "\n",
    "```R\n",
    "# Load necessary libraries\n",
    "library(\"mlr3verse\")\n",
    "library(\"mlr3learners\")\n",
    "library(\"mlr3tuning\")\n",
    "library(\"data.table\")\n",
    "library(\"ggplot2\")\n",
    "\n",
    "# Set logging threshold for mlr3 to warning level\n",
    "lgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n",
    "\n",
    "# Load the German Credit dataset from rchallenge package\n",
    "# install rchallenge package if not install\n",
    "data(\"german\", package = \"rchallenge\")\n",
    "\n",
    "# Create a classification task with target variable 'credit_risk'\n",
    "task = as_task_classif(german, id = \"GermanCredit\", target = \"credit_risk\")\n",
    "\n",
    "# Define preprocessing steps as a pipeline\n",
    "preprocess <- po(\"imputeoor\") %>>% \n",
    "  po(\"encodeimpact\", param_vals = list(impute_zero = T)) %>>%  \n",
    "  po(\"filter\", flt(\"auc\")) %>>%  \n",
    "  po(\"filter\", flt(\"find_correlation\", method = \"spearman\", use = \"na.or.complete\"))\n",
    "\n",
    "# Set parameter values for preprocessing steps\n",
    "preprocess$param_set$values$auc.filter.frac <- 0.5\n",
    "preprocess$param_set$values$find_correlation.filter.frac <- 0.5\n",
    "\n",
    "# Define the learner (LightGBM)\n",
    "learner <- lrn(\"classif.lightgbm\", num_iterations = 100)\n",
    "\n",
    "# Define the pipeline by combining preprocessing and the learner\n",
    "pipeline <- preprocess %>>% learner\n",
    "\n",
    "# Create a GraphLearner to encapsulate the pipeline\n",
    "model <- GraphLearner$new(pipeline)\n",
    "\n",
    "# Train the model\n",
    "model$train(task)\n",
    "\n",
    "# Make predictions\n",
    "predictions <- model$predict(task)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Convert the MLR3 LightGBM model to Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract preprocessing\n",
    "\n",
    "Extract the results of tuning for imputeoor and encodeimpact steps from the model\n",
    "\n",
    "```R\n",
    "f_extract_impute <- function(col){\n",
    "  val <- model$state$model$imputeoor$model[col][[col]]\n",
    "  val\n",
    "}\n",
    "```\n",
    "\n",
    "```R\n",
    "f_extract_encodeimpact <- function(col) {\n",
    "  df <- model$state$model$encodeimpact$impact[col]\n",
    "  df <- as.data.frame(df)\n",
    "  df\n",
    "}\n",
    "```\n",
    "\n",
    "*Note: check final model in lightgbm model and only create preprocessing with them*\n",
    "\n",
    "```R\n",
    "# Access the classif.lightgbm learner model\n",
    "model$state$model$classif.lightgbm\n",
    "```\n",
    "\n",
    "<TaskClassif:GermanCredit> (1000 x 10)\n",
    "* Target: credit_risk\n",
    "* Properties: twoclass\n",
    "* Features (9):\n",
    "  - dbl (7): credit_history.good, employment_duration.good, housing.good, personal_status_sex.bad, purpose.good,\n",
    "    savings.good, status.good\n",
    "  - int (2): age, amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Save LightGBM model\n",
    "\n",
    "```R\n",
    "# Extract the trained LightGBM model from the pipeline\n",
    "lightgbm_model <- model$state$model$classif.lightgbm$model\n",
    "\n",
    "# Specify the filename for saving the LightGBM model\n",
    "model_file <- \"lightgbm_model.txt\"\n",
    "\n",
    "# Save the LightGBM model to a file\n",
    "lgb.save(lightgbm_model, model_file)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create preprocessing function in python\n",
    "\n",
    "```python\n",
    "# Function to impute values\n",
    "def f_impute_values(missing_df):\n",
    "    # Select the desired columns in the specified order\n",
    "    sel_features = [\n",
    "          \"credit_history.good\", \"employment_duration.good\", \"housing.good\",\n",
    "            \"personal_status_sex.bad\", \"purpose.good\", \"savings.good\", \"status.good\",\n",
    "            \"age\", \"amount\"\n",
    "    ]\n",
    "    \n",
    "    # Sample data with feature names and impute values\n",
    "    impute_data = pd.DataFrame({\n",
    "        'featureName': [\"age\", \"amount\"],\n",
    "        'impute_value': [-38, -17925]\n",
    "    })\n",
    "\n",
    "    # Filter impute_data to include only feature names that exist in missing_df\n",
    "    impute_data = impute_data[impute_data['featureName'].isin(missing_df.columns)]\n",
    "\n",
    "    # Create a dictionary of feature names and their impute values\n",
    "    impute_dict = dict(zip(impute_data['featureName'], impute_data['impute_value']))\n",
    "\n",
    "    # Impute missing values in missing_df based on the impute_dict\n",
    "    missing_df.fillna(impute_dict, inplace=True)\n",
    "\n",
    "    # Select the desired columns in the specified order\n",
    "    missing_df = missing_df[sel_features]\n",
    "\n",
    "    return missing_df\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Transfer the saved model file (\"lightgbm_model.txt\") from R to your Python environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, use the LightGBM library to load the model from the saved file and make predictions. You'll also need to load any necessary libraries and install LightGBM if you haven't already:\n",
    "\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved LightGBM model from the file\n",
    "model = lgb.Booster(model_file='lightgbm_model.txt')\n",
    "\n",
    "# Load your new data for prediction as a pandas DataFrame\n",
    "# Replace 'new_data.csv' with the actual path to your data file\n",
    "new_data = pd.read_csv('new_data.csv')\n",
    "\n",
    "# preprocessing\n",
    "imputed_df = f_impute_values(train_df)\n",
    "\n",
    "# Make predictions on the new data\n",
    "predictions = model.predict(imputed_df)\n",
    "\n",
    "# The 'predictions' variable now contains the model's predictions for the new data\n",
    "```\n",
    "\n",
    "Make sure to replace `'new_data.csv'` with the actual path to your new data file in the `pd.read_csv` line.\n",
    "\n",
    "With these steps, you can load the MLR3 LightGBM model in Python, and then use it to make predictions on new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fc7d2c5e3b32912b68ef575c1bdd2ee7ee3f28f2d636d660b71751dc8fb34a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
